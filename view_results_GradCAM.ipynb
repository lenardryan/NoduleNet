{"cells":[{"cell_type":"markdown","metadata":{"id":"EWUj0cRctaO3"},"source":["### Mount Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68692,"status":"ok","timestamp":1676895012004,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"VsH8UstYtZKS","outputId":"ad964031-ce27-43c5-f75d-4613e4aad5b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"OOtoePpJtiWj"},"source":["### Check GPU Info"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1233,"status":"ok","timestamp":1676895013228,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"vYjIHr72tj1m","outputId":"b9aad82d-9dd4-4194-878e-5c9ac824a4ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Feb 20 12:10:10 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   62C    P0    31W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","metadata":{"id":"pU3j1Rnwt_qZ"},"source":["### Install Dependencies"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7959,"status":"ok","timestamp":1676895021183,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"3EiyLP4HuBYe","outputId":"934824c7-4123-4eca-930c-2a513659970f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting setuptools==59.5.0\n","  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m952.4/952.4 KB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: setuptools\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed setuptools-59.5.0\n"]}],"source":["!pip install setuptools==59.5.0"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6872,"status":"ok","timestamp":1676895028044,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"jfz_sZFzuB1i","outputId":"fb203103-09d5-4438-eff9-ba23ef33a185"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pydicom\n","  Downloading pydicom-2.3.1-py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydicom\n","Successfully installed pydicom-2.3.1\n"]}],"source":["!pip install pydicom"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2958,"status":"ok","timestamp":1676895030968,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"V70rFNENuDO7","outputId":"b49968bb-f851-479c-e187-0e35a026cd3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ninja\n","  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ninja\n","Successfully installed ninja-1.11.1\n"]}],"source":["!pip install ninja"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8323,"status":"ok","timestamp":1676895039284,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"x6BqCvimuEkR","outputId":"cb939f52-971d-43fa-b3d7-4b73197c7f3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pynrrd\n","  Downloading pynrrd-1.0.0-py2.py3-none-any.whl (19 kB)\n","Collecting SimpleITK\n","  Downloading SimpleITK-2.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from pynrrd) (4.5.0)\n","Collecting nptyping\n","  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from pynrrd) (1.21.6)\n","Installing collected packages: SimpleITK, nptyping, pynrrd\n","Successfully installed SimpleITK-2.2.1 nptyping-2.4.1 pynrrd-1.0.0\n"]}],"source":["!pip install pynrrd SimpleITK"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6640,"status":"ok","timestamp":1676895045905,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"oF4Pzr9GuI0u","outputId":"2107fba5-44f0-4fea-b651-a823b5ca9cce"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Skipping tb-nightly as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Skipping tensorboardX as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0mFound existing installation: tensorboard 2.11.2\n","Uninstalling tensorboard-2.11.2:\n","  Successfully uninstalled tensorboard-2.11.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboard\n","  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.51.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.16.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.8.1)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0\n","  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.19.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (3.4.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.38.4)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (1.21.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (2.25.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard) (59.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard) (6.0.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.13.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.2)\n","Installing collected packages: tensorboard-data-server, tensorboard\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.6.1\n","    Uninstalling tensorboard-data-server-0.6.1:\n","      Successfully uninstalled tensorboard-data-server-0.6.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.11.0 requires tensorboard<2.12,>=2.11, but you have tensorboard 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorboard-2.12.0 tensorboard-data-server-0.7.0\n"]}],"source":["!pip uninstall --yes tb-nightly tensorboardX tensorboard\n","!pip install tensorboard"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9227,"status":"ok","timestamp":1676895055122,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"qoVDxx7-C6KX","outputId":"fe567a63-f66b-4892-a241-5c393b1a0b36"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting medcam\n","  Downloading medcam-0.1.21.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from medcam) (2022.12.7)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.8/dist-packages (from medcam) (0.11.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from medcam) (4.4.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from medcam) (0.16.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from medcam) (2.9.0)\n","Requirement already satisfied: kiwisolver in /usr/local/lib/python3.8/dist-packages (from medcam) (1.4.4)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Markdown in /usr/local/lib/python3.8/dist-packages (from medcam) (3.4.1)\n","Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.8/dist-packages (from medcam) (2.0.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from medcam) (3.2.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from medcam) (3.0)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.8/dist-packages (from medcam) (3.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from medcam) (1.21.6)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from medcam) (23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from medcam) (1.3.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from medcam) (7.1.2)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from medcam) (3.0.9)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from medcam) (2.8.2)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from medcam) (2022.7.1)\n","Requirement already satisfied: PyWavelets in /usr/local/lib/python3.8/dist-packages (from medcam) (1.4.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from medcam) (0.18.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from medcam) (1.7.3)\n","Requirement already satisfied: SimpleITK in /usr/local/lib/python3.8/dist-packages (from medcam) (2.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from medcam) (1.15.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from Markdown->medcam) (6.0.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->medcam) (2023.2.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->Markdown->medcam) (3.13.0)\n","Building wheels for collected packages: medcam\n","  Building wheel for medcam (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for medcam: filename=medcam-0.1.21-py3-none-any.whl size=23214 sha256=d75ea97eeed9b1aa286d0c0c99ad1a6e9aa5e17681c5915a11c54b66669b0341\n","  Stored in directory: /root/.cache/pip/wheels/98/da/39/4705b259cd88818af023a6021dbbbe5e97863b2fdc9b965109\n","Successfully built medcam\n","Installing collected packages: Mako, medcam\n","Successfully installed Mako-1.2.4 medcam-0.1.21\n"]}],"source":["!pip install medcam"]},{"cell_type":"code","source":["!pip install grad-cam"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKLavON_WlSW","executionInfo":{"status":"ok","timestamp":1676895066888,"user_tz":-480,"elapsed":11776,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"bcec193e-9872-482f-abfb-b686089f991f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting grad-cam\n","  Downloading grad-cam-1.4.6.tar.gz (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from grad-cam) (1.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from grad-cam) (4.64.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from grad-cam) (4.6.0.66)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from grad-cam) (7.1.2)\n","Collecting ttach\n","  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from grad-cam) (1.13.1+cu116)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from grad-cam) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from grad-cam) (1.21.6)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from grad-cam) (0.14.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.1->grad-cam) (4.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.8.2->grad-cam) (2.25.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->grad-cam) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->grad-cam) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->grad-cam) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->grad-cam) (0.11.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->grad-cam) (1.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->grad-cam) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->grad-cam) (3.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->grad-cam) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (4.0.0)\n","Building wheels for collected packages: grad-cam\n","  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for grad-cam: filename=grad_cam-1.4.6-py3-none-any.whl size=38261 sha256=53db4f8e70e00f20bd6994acd7e1605df078ea5751052c16c4857f04e6538e9a\n","  Stored in directory: /root/.cache/pip/wheels/53/02/43/1f75726b5c28459596067ad91e36951463c01273eef661f09f\n","Successfully built grad-cam\n","Installing collected packages: ttach, grad-cam\n","Successfully installed grad-cam-1.4.6 ttach-0.0.3\n"]}]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoEXVjUfelur","executionInfo":{"status":"ok","timestamp":1676895071022,"user_tz":-480,"elapsed":4139,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"c6b1b8e7-0164-4311-e1fe-641229e69a6d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting captum\n","  Downloading captum-0.6.0-py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from captum) (1.13.1+cu116)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from captum) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from captum) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->captum) (4.5.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->captum) (0.11.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n","Installing collected packages: captum\n","Successfully installed captum-0.6.0\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1957,"status":"ok","timestamp":1676895072936,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"rmhxtqq2uLYG","outputId":"81731451-1739-4a2b-addb-74f4287cb207"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Thesis/NoduleNet/build/box\n"]}],"source":["cd '/content/drive/MyDrive/Thesis/NoduleNet/build/box'"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47213,"status":"ok","timestamp":1676895120140,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"SFCLK9aZuOj8","outputId":"fe9ec417-5e43-431a-dcc9-1aa8b006e3da"},"outputs":[{"output_type":"stream","name":"stdout","text":["running install\n","/usr/local/lib/python3.8/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n","  warnings.warn(\n","running bdist_egg\n","running egg_info\n","writing box.egg-info/PKG-INFO\n","writing dependency_links to box.egg-info/dependency_links.txt\n","writing top-level names to box.egg-info/top_level.txt\n","reading manifest file 'box.egg-info/SOURCES.txt'\n","writing manifest file 'box.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_ext\n","building 'box' extension\n","Emitting ninja build file /content/drive/MyDrive/Thesis/NoduleNet/build/box/build/temp.linux-x86_64-3.8/build.ninja...\n","Compiling objects...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","[1/1] c++ -MMD -MF /content/drive/MyDrive/Thesis/NoduleNet/build/box/build/temp.linux-x86_64-3.8/box.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/torch/include -I/usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.8/dist-packages/torch/include/TH -I/usr/local/lib/python3.8/dist-packages/torch/include/THC -I/usr/include/python3.8 -c -c /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp -o /content/drive/MyDrive/Thesis/NoduleNet/build/box/build/temp.linux-x86_64-3.8/box.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=box -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:4:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/nms.cpp: In function ‘int cpu_nms(at::Tensor*, at::Tensor*, at::Tensor*, at::Tensor*, at::Tensor*, float)’:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/nms.cpp:16:47: warning: ‘T* at::Tensor::data() const [with T = long int]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   16 |     auto keep_out_flat = keep_out->data<long>();\n","      |                                               ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:4:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/nms.cpp:17:42: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   17 |     auto boxes_flat = boxes->data<float>();\n","      |                                          ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:4:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/nms.cpp:18:41: warning: ‘T* at::Tensor::data() const [with T = long int]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   18 |     auto order_flat = order->data<long>();\n","      |                                         ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:4:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/nms.cpp:19:43: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   19 |     auto areas_flat =  areas->data<float>();\n","      |                                           ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:4:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/nms.cpp:22:49: warning: ‘T* at::Tensor::data() const [with T = int]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   22 |     auto suppressed_flat = suppressed.data<int>();\n","      |                                                 ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:4:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/nms.cpp:96:45: warning: ‘T* at::Tensor::data() const [with T = long int]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   96 |     auto num_out_flat = num_out->data<long>();\n","      |                                             ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:5:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/overlap.cpp: In function ‘int cpu_overlap(at::Tensor*, at::Tensor*, at::Tensor*)’:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/overlap.cpp:23:44: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   23 |     auto boxes1_flat = boxes1->data<float>();\n","      |                                            ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:5:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/overlap.cpp:24:44: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   24 |     auto boxes2_flat = boxes2->data<float>();\n","      |                                            ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:5:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/overlap.cpp:25:46: warning: ‘T* at::Tensor::data() const [with T = float]’ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [-Wdeprecated-declarations]\n","   25 |     auto overlap_flat = overlap->data<float>();\n","      |                                              ^\n","In file included from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/ATen/Tensor.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n","                 from /usr/local/lib/python3.8/dist-packages/torch/include/torch/extension.h:4,\n","                 from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:1:\n","/usr/local/lib/python3.8/dist-packages/torch/include/ATen/core/TensorBody.h:238:7: note: declared here\n","  238 |   T * data() const {\n","      |       ^~~~\n","In file included from /content/drive/MyDrive/Thesis/NoduleNet/build/box/box.cpp:5:\n","/content/drive/MyDrive/Thesis/NoduleNet/build/box/overlap.cpp:20:10: warning: unused variable ‘overlap_num’ [-Wunused-variable]\n","   20 |     long overlap_num = overlap->sizes()[0];\n","      |          ^~~~~~~~~~~\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/drive/MyDrive/Thesis/NoduleNet/build/box/build/temp.linux-x86_64-3.8/box.o -L/usr/local/lib/python3.8/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.8/box.cpython-38-x86_64-linux-gnu.so\n","creating build/bdist.linux-x86_64/egg\n","copying build/lib.linux-x86_64-3.8/box.cpython-38-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n","creating stub loader for box.cpython-38-x86_64-linux-gnu.so\n","byte-compiling build/bdist.linux-x86_64/egg/box.py to box.cpython-38.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying box.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying box.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying box.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying box.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n","zip_safe flag not set; analyzing archive contents...\n","__pycache__.box.cpython-38: module references __file__\n","creating 'dist/box-0.0.0-py3.8-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing box-0.0.0-py3.8-linux-x86_64.egg\n","creating /usr/local/lib/python3.8/dist-packages/box-0.0.0-py3.8-linux-x86_64.egg\n","Extracting box-0.0.0-py3.8-linux-x86_64.egg to /usr/local/lib/python3.8/dist-packages\n","Adding box 0.0.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.8/dist-packages/box-0.0.0-py3.8-linux-x86_64.egg\n","Processing dependencies for box==0.0.0\n","Finished processing dependencies for box==0.0.0\n"]}],"source":["!python setup.py install"]},{"cell_type":"markdown","metadata":{"id":"Fjq4apG5t6fC"},"source":["### Import Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1676896002536,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"pxPKzzXHtcme","outputId":"ad264e70-2e77-433d-95ae-ee9335475dfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Thesis/NoduleNet\n"]}],"source":["cd '/content/drive/MyDrive/Thesis/NoduleNet'"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"GKJ_2GF6tnI-","executionInfo":{"status":"ok","timestamp":1676896009182,"user_tz":-480,"elapsed":6651,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import os\n","import traceback\n","import time\n","import nrrd\n","import sys\n","import matplotlib.pyplot as plt\n","import logging\n","import argparse\n","import torch.nn.functional as F\n","import SimpleITK as sitk\n","from scipy.stats import norm\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","from torch.autograd import Variable\n","from torch.nn.parallel.data_parallel import data_parallel\n","import torch.nn as nn\n","from scipy.ndimage.measurements import label\n","from scipy.ndimage import center_of_mass\n","from net.nodule_net import NoduleNet\n","from dataset.collate import train_collate, test_collate, eval_collate\n","from dataset.bbox_reader import BboxReader\n","from dataset.mask_reader import MaskReader\n","from config import config\n","from utils.visualize import draw_gt, draw_pred, generate_image_anim, show_image_and_mask, show_cam, draw_ground_truth, draw_bboxes, draw_one_bbox, show3D_comparison\n","from utils.util import dice_score_seperate, get_contours_from_masks, merge_contours, hausdorff_distance\n","from utils.util import onehot2multi_mask, normalize, pad2factor, load_dicom_image, crop_boxes2mask_single, crop_boxes2mask, crop_boxes2cam, npy2submission\n","import pandas as pd\n","from evaluationScript.noduleCADEvaluationLUNA16 import noduleCADEvaluation\n","from collections import OrderedDict\n","from PIL import Image\n","import cv2\n","# from pytorch_grad_cam import GradCAM, HiResCAM, GradCAMElementWise, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YRqremPYup2T","executionInfo":{"status":"ok","timestamp":1676896009183,"user_tz":-480,"elapsed":38,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (24, 16)\n","plt.switch_backend('agg')\n","this_module = sys.modules[__name__]\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'\n","\n","device = torch.device(\"cuda\")"]},{"cell_type":"markdown","metadata":{"id":"6s6JH8jTwehZ"},"source":["### Load parameters"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"J2CBgAD8vFMV","executionInfo":{"status":"ok","timestamp":1676896009184,"user_tz":-480,"elapsed":37,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"outputs":[],"source":["data_dir = config['preprocessed_data_dir']\n","test_set_name = config['test_set_name']\n","num_workers = 0\n","initial_checkpoint = config['initial_checkpoint']\n","net = config['net']\n","out_dir = config['out_dir']\n","\n","net = getattr(this_module, net)(config)\n","net = net.to(device)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1676896009185,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"ZUKjIdTmv_-O","outputId":"b6b5a97c-70f9-45a4-934f-cb9057dab404"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Loading model from /content/drive/MyDrive/Thesis/NoduleNet/results/cross_val_test/model/167.ckpt]\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":5}],"source":["print('[Loading model from %s]' % initial_checkpoint)\n","checkpoint = torch.load(initial_checkpoint)\n","# out_dir = checkpoint['out_dir']\n","epoch = checkpoint['epoch']\n","\n","net.load_state_dict(checkpoint['state_dict'])\n","# net = medcam.inject(net, output_dir=\"/content/drive/MyDrive/Thesis/NoduleNet/results/attention_maps\", save_maps=True)"]},{"cell_type":"markdown","metadata":{"id":"7Qp2c1N-wjHV"},"source":["### Load Test Dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1676896009187,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"vdE2w3r_wKRW","outputId":"41022f51-d40e-43b0-934c-b3c009404692"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'dataset.mask_reader.MaskReader'>\n"]}],"source":["dataset = MaskReader(data_dir, test_set_name, config, mode='eval')\n","print(type(dataset))"]},{"cell_type":"markdown","metadata":{"id":"OfT9EZBZ6s7V"},"source":["### Get Test Data"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"em6IZGflwVcR","executionInfo":{"status":"ok","timestamp":1676896009188,"user_tz":-480,"elapsed":28,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"outputs":[],"source":["net.set_mode('eval')\n","net.use_mask = True\n","net.use_rcnn = True\n","# raw_dir = config['data_dir']\n","# preprocessed_dir = config['preprocessed_data_dir']"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1676896009189,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"fgnQZxJM5de4","outputId":"fcb2f5ee-8a49-4736-fa53-675ab24a22fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total # of eval data: 41\n"]}],"source":["print('Total # of eval data: %d' % (len(dataset)))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1676896009190,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"},"user_tz":-480},"id":"OlIJqIPF6G2Z","outputId":"48102d74-7471-4721-c851-2915a7ee4a7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test set index: 3\n"]}],"source":["import random\n","from random import randrange\n","\n","i = randrange(len(dataset))\n","print(\"Test set index:\", i)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1WKicZnv6n-i","executionInfo":{"status":"ok","timestamp":1676896014864,"user_tz":-480,"elapsed":5692,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"outputs":[],"source":["(input, truth_bboxes, truth_labels, truth_masks, mask, image) = (dataset[i][0], dataset[i][1], dataset[i][2], dataset[i][3], dataset[i][4], dataset[i][5])"]},{"cell_type":"markdown","source":["###GradCAM"],"metadata":{"id":"MHnETixPdUkE"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"F6kzOTDZUFNc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676896014866,"user_tz":-480,"elapsed":74,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"c7c0d1c6-03ec-44be-ffcd-b87f0ed78f76"},"outputs":[{"output_type":"stream","name":"stdout","text":["MaskHead(\n","  (up1): Sequential(\n","    (0): Upsample(scale_factor=2.0, mode=trilinear)\n","    (1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (3): ReLU(inplace=True)\n","  )\n","  (up2): Sequential(\n","    (0): Upsample(scale_factor=2.0, mode=trilinear)\n","    (1): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (3): ReLU(inplace=True)\n","  )\n","  (up3): Sequential(\n","    (0): Upsample(scale_factor=2.0, mode=trilinear)\n","    (1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (2): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (3): ReLU(inplace=True)\n","  )\n","  (back1): Sequential(\n","    (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (2): ReLU(inplace=True)\n","  )\n","  (back2): Sequential(\n","    (0): Conv3d(96, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (2): ReLU(inplace=True)\n","  )\n","  (back3): Sequential(\n","    (0): Conv3d(65, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n","    (2): ReLU(inplace=True)\n","  )\n","  (logits1): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n","  (logits2): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",")\n"]}],"source":["print(net.mask_head)"]},{"cell_type":"code","source":["def get_feat_vector(img, model):\n","    '''\n","    Input: \n","        img: tensor, input image\n","        model: torch model\n","    Output:\n","        my_output: torch.tensor, output of avgpool layer\n","    '''\n","\n","    with torch.no_grad():\n","        activation = {}\n","        \n","        def get_forward(name):\n","          def hook(model, input, output):\n","              activation[name] = output.detach()\n","          return hook\n","\n","        def get_backward(name):\n","          def hook(model, input, output):\n","              activation[name] = output[0].detach()\n","          return hook\n","\n","        f_hook = model.rpn.conv[0].register_forward_hook(get_forward('forward')) \n","        b_hook = model.rpn.conv[0].register_forward_hook(get_backward('backward'))        \n","        model.forward_pred(img)\n","        # model.loss.total_loss.backward()\n","        f_hook.remove()\n","        b_hook.remove()\n","        return activation['forward'], activation['backward']"],"metadata":{"id":"ZA4Lv2-6grqS","executionInfo":{"status":"ok","timestamp":1676896014867,"user_tz":-480,"elapsed":70,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["input = input.cuda().unsqueeze(0)\n","my_forward, my_backward = get_feat_vector(input, net)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AW1aIN82gblt","executionInfo":{"status":"ok","timestamp":1676896027515,"user_tz":-480,"elapsed":12717,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"7b9f4ec3-053e-4624-847e-dc1c28ab7646"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/content/drive/MyDrive/Thesis/NoduleNet/net/layer/rcnn_nms.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(logits).cpu().data.numpy()\n","/content/drive/MyDrive/Thesis/NoduleNet/net/layer/rcnn_nms.py:117: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(logits).cpu().data.numpy()\n","/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"]}]},{"cell_type":"code","source":["print(my_backward.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycdJY_hsg3KU","executionInfo":{"status":"ok","timestamp":1676896027517,"user_tz":-480,"elapsed":35,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"779e7eef-647a-4a34-a874-4019f51b8e35"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([64, 76, 56, 76])\n"]}]},{"cell_type":"code","source":["castConvOutputs = my_forward.to(torch.float32)\n","castGrads = my_backward.to(torch.float32)\n","guidedGrads = castConvOutputs * castGrads * my_backward"],"metadata":{"id":"TLG5tb4YiX1m","executionInfo":{"status":"ok","timestamp":1676896027518,"user_tz":-480,"elapsed":31,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["guidedGrads.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qew9bdCziqle","executionInfo":{"status":"ok","timestamp":1676896027519,"user_tz":-480,"elapsed":31,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"dfbbaed3-05ac-46fa-e1ed-4517dff23f4e"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 64, 76, 56, 76])"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["convOutputs = my_forward[0,...]\n","guidedGrads = guidedGrads[0,...]"],"metadata":{"id":"yCxB0afKi2Sy","executionInfo":{"status":"ok","timestamp":1676896027520,"user_tz":-480,"elapsed":26,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["weights = guidedGrads.mean(axis=(0)) \n","cam = (weights * my_forward).sum(axis=1)[0,...]"],"metadata":{"id":"Gg3ot89Ti7qa","executionInfo":{"status":"ok","timestamp":1676896027521,"user_tz":-480,"elapsed":26,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["print(cam.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6E5pEL-mvBw","executionInfo":{"status":"ok","timestamp":1676896027522,"user_tz":-480,"elapsed":26,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"5493b1cf-c124-49c1-87a0-061746ad17ad"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([76, 56, 76])\n"]}]},{"cell_type":"code","source":["(d,h,w) = (input.shape[2], input.shape[3], input.shape[4])"],"metadata":{"id":"k66lcuytjymk","executionInfo":{"status":"ok","timestamp":1676896027523,"user_tz":-480,"elapsed":22,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["zoom = int(d / cam.shape[0])\n","print(zoom)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmTXuwltoJGK","executionInfo":{"status":"ok","timestamp":1676896027523,"user_tz":-480,"elapsed":22,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"52dd6c32-75f1-41bf-dac5-1e680ddb05d7"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["4\n"]}]},{"cell_type":"code","source":["import scipy.ndimage\n","heatmap = scipy.ndimage.zoom(cam.cpu().numpy(), zoom, order=1)"],"metadata":{"id":"IRMm6N8WkoiD","executionInfo":{"status":"ok","timestamp":1676896029177,"user_tz":-480,"elapsed":1671,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["numer = heatmap - np.min(heatmap)\n","denom = (heatmap.max() - heatmap.min())\n","heatmap = numer / denom\n","heatmap = 1 - heatmap"],"metadata":{"id":"3La-xNaUkz7s","executionInfo":{"status":"ok","timestamp":1676896029178,"user_tz":-480,"elapsed":30,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["heatmap = np.uint8(255 * heatmap)[..., np.newaxis]\n","# heatmap = heatmap[..., np.newaxis]\n","heatmap.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__RfLWmd3gXH","executionInfo":{"status":"ok","timestamp":1676896029179,"user_tz":-480,"elapsed":30,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"23b5348a-7f32-4d40-eace-43ca9530256c"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(304, 224, 304, 1)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["heatmap_stack = np.zeros((len(heatmap), heatmap.shape[1], heatmap.shape[2], 3))\n","heatmap_stack.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmgrR4wg-UFd","executionInfo":{"status":"ok","timestamp":1676896029180,"user_tz":-480,"elapsed":28,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"959f39c4-3f1a-48a8-af67-b68d12edc0c7"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(304, 224, 304, 3)"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["for idx in range(len(heatmap)):\n","  # print(idx)\n","  img = heatmap[idx,...]\n","  heatmap_img = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n","  heatmap_stack[idx,...] = heatmap_img"],"metadata":{"id":"Ab5piiIH8ndp","executionInfo":{"status":"ok","timestamp":1676896029181,"user_tz":-480,"elapsed":23,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(heatmap_stack.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11LKUYvGEeuJ","executionInfo":{"status":"ok","timestamp":1676896029182,"user_tz":-480,"elapsed":23,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"4fab7935-dd84-48d6-d125-d82fae081702"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["(304, 224, 304, 3)\n"]}]},{"cell_type":"code","source":["img = input[0,0,...].cpu().numpy()[..., np.newaxis]\n","# img = img[..., np.newaxis]\n","img.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObwkiAxBAPVC","executionInfo":{"status":"ok","timestamp":1676896029183,"user_tz":-480,"elapsed":19,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"a8e00708-801a-41ad-8bdb-0538c1f9dcd9"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(304, 224, 304, 1)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["superimposed_img = img + (heatmap_stack * 0.4)"],"metadata":{"id":"5dq7hw9iA00N","executionInfo":{"status":"ok","timestamp":1676896029777,"user_tz":-480,"elapsed":608,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["%matplotlib inline\n","# show_image_and_mask(input[0,0,...].cpu().numpy() + heatmap)\n","# show_cam(input[0,0,...].cpu().numpy(), heatmap)\n","show_image_and_mask(superimposed_img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319,"referenced_widgets":["64285efdca534a1788411dceda383496","54fe7eefe59649579a9cd0d4c44ec649","95aca59cd8374097b31e9f6cf67a8f3d","7f5754ac21f44b1683e6f1dcc16800c1","6d0b25c554f647b49bda7dcf3c5e1944","13c00f3803a946cd9542adac0dd1f05e","d10f302810264cb4a24776a0c53c12b4"]},"id":"NjYq56wBg9dl","executionInfo":{"status":"ok","timestamp":1676896031102,"user_tz":-480,"elapsed":1340,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"884d5e79-b8ba-4514-f4cb-56a7500a9c54"},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":["interactive(children=(IntSlider(value=0, description='k', max=303), Output()), _dom_classes=('widget-interact'…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64285efdca534a1788411dceda383496"}},"metadata":{}}]},{"cell_type":"code","source":["%matplotlib notebook\n","%matplotlib notebook\n","generate_image_anim(superimposed_img, save_path='/content/drive/MyDrive/Thesis/NoduleNet/results/gradcam_results.mp4')"],"metadata":{"id":"MtirNzM7kmSR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1676896065028,"user_tz":-480,"elapsed":33977,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}},"outputId":"6041adc3-1e22-4b15-ccd3-9759ffdc51cf"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div id='d16d1daa-47f0-4257-b131-4be0d920955c'></div>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.animation.ArtistAnimation at 0x7fbdd9f0b400>"]},"metadata":{},"execution_count":31},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["/* Put everything inside the global mpl namespace */\n","window.mpl = {};\n","\n","\n","mpl.get_websocket_type = function() {\n","    if (typeof(WebSocket) !== 'undefined') {\n","        return WebSocket;\n","    } else if (typeof(MozWebSocket) !== 'undefined') {\n","        return MozWebSocket;\n","    } else {\n","        alert('Your browser does not have WebSocket support. ' +\n","              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n","              'Firefox 4 and 5 are also supported but you ' +\n","              'have to enable WebSockets in about:config.');\n","    };\n","}\n","\n","mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n","    this.id = figure_id;\n","\n","    this.ws = websocket;\n","\n","    this.supports_binary = (this.ws.binaryType != undefined);\n","\n","    if (!this.supports_binary) {\n","        var warnings = document.getElementById(\"mpl-warnings\");\n","        if (warnings) {\n","            warnings.style.display = 'block';\n","            warnings.textContent = (\n","                \"This browser does not support binary websocket messages. \" +\n","                    \"Performance may be slow.\");\n","        }\n","    }\n","\n","    this.imageObj = new Image();\n","\n","    this.context = undefined;\n","    this.message = undefined;\n","    this.canvas = undefined;\n","    this.rubberband_canvas = undefined;\n","    this.rubberband_context = undefined;\n","    this.format_dropdown = undefined;\n","\n","    this.image_mode = 'full';\n","\n","    this.root = $('<div/>');\n","    this._root_extra_style(this.root)\n","    this.root.attr('style', 'display: inline-block');\n","\n","    $(parent_element).append(this.root);\n","\n","    this._init_header(this);\n","    this._init_canvas(this);\n","    this._init_toolbar(this);\n","\n","    var fig = this;\n","\n","    this.waiting = false;\n","\n","    this.ws.onopen =  function () {\n","            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n","            fig.send_message(\"send_image_mode\", {});\n","            if (mpl.ratio != 1) {\n","                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n","            }\n","            fig.send_message(\"refresh\", {});\n","        }\n","\n","    this.imageObj.onload = function() {\n","            if (fig.image_mode == 'full') {\n","                // Full images could contain transparency (where diff images\n","                // almost always do), so we need to clear the canvas so that\n","                // there is no ghosting.\n","                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n","            }\n","            fig.context.drawImage(fig.imageObj, 0, 0);\n","        };\n","\n","    this.imageObj.onunload = function() {\n","        fig.ws.close();\n","    }\n","\n","    this.ws.onmessage = this._make_on_message_function(this);\n","\n","    this.ondownload = ondownload;\n","}\n","\n","mpl.figure.prototype._init_header = function() {\n","    var titlebar = $(\n","        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n","        'ui-helper-clearfix\"/>');\n","    var titletext = $(\n","        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n","        'text-align: center; padding: 3px;\"/>');\n","    titlebar.append(titletext)\n","    this.root.append(titlebar);\n","    this.header = titletext[0];\n","}\n","\n","\n","\n","mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n","\n","}\n","\n","\n","mpl.figure.prototype._root_extra_style = function(canvas_div) {\n","\n","}\n","\n","mpl.figure.prototype._init_canvas = function() {\n","    var fig = this;\n","\n","    var canvas_div = $('<div/>');\n","\n","    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n","\n","    function canvas_keyboard_event(event) {\n","        return fig.key_event(event, event['data']);\n","    }\n","\n","    canvas_div.keydown('key_press', canvas_keyboard_event);\n","    canvas_div.keyup('key_release', canvas_keyboard_event);\n","    this.canvas_div = canvas_div\n","    this._canvas_extra_style(canvas_div)\n","    this.root.append(canvas_div);\n","\n","    var canvas = $('<canvas/>');\n","    canvas.addClass('mpl-canvas');\n","    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n","\n","    this.canvas = canvas[0];\n","    this.context = canvas[0].getContext(\"2d\");\n","\n","    var backingStore = this.context.backingStorePixelRatio ||\n","\tthis.context.webkitBackingStorePixelRatio ||\n","\tthis.context.mozBackingStorePixelRatio ||\n","\tthis.context.msBackingStorePixelRatio ||\n","\tthis.context.oBackingStorePixelRatio ||\n","\tthis.context.backingStorePixelRatio || 1;\n","\n","    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n","\n","    var rubberband = $('<canvas/>');\n","    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n","\n","    var pass_mouse_events = true;\n","\n","    canvas_div.resizable({\n","        start: function(event, ui) {\n","            pass_mouse_events = false;\n","        },\n","        resize: function(event, ui) {\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","        stop: function(event, ui) {\n","            pass_mouse_events = true;\n","            fig.request_resize(ui.size.width, ui.size.height);\n","        },\n","    });\n","\n","    function mouse_event_fn(event) {\n","        if (pass_mouse_events)\n","            return fig.mouse_event(event, event['data']);\n","    }\n","\n","    rubberband.mousedown('button_press', mouse_event_fn);\n","    rubberband.mouseup('button_release', mouse_event_fn);\n","    // Throttle sequential mouse events to 1 every 20ms.\n","    rubberband.mousemove('motion_notify', mouse_event_fn);\n","\n","    rubberband.mouseenter('figure_enter', mouse_event_fn);\n","    rubberband.mouseleave('figure_leave', mouse_event_fn);\n","\n","    canvas_div.on(\"wheel\", function (event) {\n","        event = event.originalEvent;\n","        event['data'] = 'scroll'\n","        if (event.deltaY < 0) {\n","            event.step = 1;\n","        } else {\n","            event.step = -1;\n","        }\n","        mouse_event_fn(event);\n","    });\n","\n","    canvas_div.append(canvas);\n","    canvas_div.append(rubberband);\n","\n","    this.rubberband = rubberband;\n","    this.rubberband_canvas = rubberband[0];\n","    this.rubberband_context = rubberband[0].getContext(\"2d\");\n","    this.rubberband_context.strokeStyle = \"#000000\";\n","\n","    this._resize_canvas = function(width, height) {\n","        // Keep the size of the canvas, canvas container, and rubber band\n","        // canvas in synch.\n","        canvas_div.css('width', width)\n","        canvas_div.css('height', height)\n","\n","        canvas.attr('width', width * mpl.ratio);\n","        canvas.attr('height', height * mpl.ratio);\n","        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n","\n","        rubberband.attr('width', width);\n","        rubberband.attr('height', height);\n","    }\n","\n","    // Set the figure to an initial 600x600px, this will subsequently be updated\n","    // upon first draw.\n","    this._resize_canvas(600, 600);\n","\n","    // Disable right mouse context menu.\n","    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n","        return false;\n","    });\n","\n","    function set_focus () {\n","        canvas.focus();\n","        canvas_div.focus();\n","    }\n","\n","    window.setTimeout(set_focus, 100);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items) {\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) {\n","            // put a spacer in here.\n","            continue;\n","        }\n","        var button = $('<button/>');\n","        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n","                        'ui-button-icon-only');\n","        button.attr('role', 'button');\n","        button.attr('aria-disabled', 'false');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","\n","        var icon_img = $('<span/>');\n","        icon_img.addClass('ui-button-icon-primary ui-icon');\n","        icon_img.addClass(image);\n","        icon_img.addClass('ui-corner-all');\n","\n","        var tooltip_span = $('<span/>');\n","        tooltip_span.addClass('ui-button-text');\n","        tooltip_span.html(tooltip);\n","\n","        button.append(icon_img);\n","        button.append(tooltip_span);\n","\n","        nav_element.append(button);\n","    }\n","\n","    var fmt_picker_span = $('<span/>');\n","\n","    var fmt_picker = $('<select/>');\n","    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n","    fmt_picker_span.append(fmt_picker);\n","    nav_element.append(fmt_picker_span);\n","    this.format_dropdown = fmt_picker[0];\n","\n","    for (var ind in mpl.extensions) {\n","        var fmt = mpl.extensions[ind];\n","        var option = $(\n","            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n","        fmt_picker.append(option);\n","    }\n","\n","    // Add hover states to the ui-buttons\n","    $( \".ui-button\" ).hover(\n","        function() { $(this).addClass(\"ui-state-hover\");},\n","        function() { $(this).removeClass(\"ui-state-hover\");}\n","    );\n","\n","    var status_bar = $('<span class=\"mpl-message\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","}\n","\n","mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n","    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n","    // which will in turn request a refresh of the image.\n","    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n","}\n","\n","mpl.figure.prototype.send_message = function(type, properties) {\n","    properties['type'] = type;\n","    properties['figure_id'] = this.id;\n","    this.ws.send(JSON.stringify(properties));\n","}\n","\n","mpl.figure.prototype.send_draw_message = function() {\n","    if (!this.waiting) {\n","        this.waiting = true;\n","        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n","    }\n","}\n","\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    var format_dropdown = fig.format_dropdown;\n","    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n","    fig.ondownload(fig, format);\n","}\n","\n","\n","mpl.figure.prototype.handle_resize = function(fig, msg) {\n","    var size = msg['size'];\n","    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n","        fig._resize_canvas(size[0], size[1]);\n","        fig.send_message(\"refresh\", {});\n","    };\n","}\n","\n","mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n","    var x0 = msg['x0'] / mpl.ratio;\n","    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n","    var x1 = msg['x1'] / mpl.ratio;\n","    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n","    x0 = Math.floor(x0) + 0.5;\n","    y0 = Math.floor(y0) + 0.5;\n","    x1 = Math.floor(x1) + 0.5;\n","    y1 = Math.floor(y1) + 0.5;\n","    var min_x = Math.min(x0, x1);\n","    var min_y = Math.min(y0, y1);\n","    var width = Math.abs(x1 - x0);\n","    var height = Math.abs(y1 - y0);\n","\n","    fig.rubberband_context.clearRect(\n","        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n","\n","    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n","}\n","\n","mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n","    // Updates the figure title.\n","    fig.header.textContent = msg['label'];\n","}\n","\n","mpl.figure.prototype.handle_cursor = function(fig, msg) {\n","    var cursor = msg['cursor'];\n","    switch(cursor)\n","    {\n","    case 0:\n","        cursor = 'pointer';\n","        break;\n","    case 1:\n","        cursor = 'default';\n","        break;\n","    case 2:\n","        cursor = 'crosshair';\n","        break;\n","    case 3:\n","        cursor = 'move';\n","        break;\n","    }\n","    fig.rubberband_canvas.style.cursor = cursor;\n","}\n","\n","mpl.figure.prototype.handle_message = function(fig, msg) {\n","    fig.message.textContent = msg['message'];\n","}\n","\n","mpl.figure.prototype.handle_draw = function(fig, msg) {\n","    // Request the server to send over a new figure.\n","    fig.send_draw_message();\n","}\n","\n","mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n","    fig.image_mode = msg['mode'];\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Called whenever the canvas gets updated.\n","    this.send_message(\"ack\", {});\n","}\n","\n","// A function to construct a web socket function for onmessage handling.\n","// Called in the figure constructor.\n","mpl.figure.prototype._make_on_message_function = function(fig) {\n","    return function socket_on_message(evt) {\n","        if (evt.data instanceof Blob) {\n","            /* FIXME: We get \"Resource interpreted as Image but\n","             * transferred with MIME type text/plain:\" errors on\n","             * Chrome.  But how to set the MIME type?  It doesn't seem\n","             * to be part of the websocket stream */\n","            evt.data.type = \"image/png\";\n","\n","            /* Free the memory for the previous frames */\n","            if (fig.imageObj.src) {\n","                (window.URL || window.webkitURL).revokeObjectURL(\n","                    fig.imageObj.src);\n","            }\n","\n","            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n","                evt.data);\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n","            fig.imageObj.src = evt.data;\n","            fig.updated_canvas_event();\n","            fig.waiting = false;\n","            return;\n","        }\n","\n","        var msg = JSON.parse(evt.data);\n","        var msg_type = msg['type'];\n","\n","        // Call the  \"handle_{type}\" callback, which takes\n","        // the figure and JSON message as its only arguments.\n","        try {\n","            var callback = fig[\"handle_\" + msg_type];\n","        } catch (e) {\n","            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n","            return;\n","        }\n","\n","        if (callback) {\n","            try {\n","                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n","                callback(fig, msg);\n","            } catch (e) {\n","                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n","            }\n","        }\n","    };\n","}\n","\n","// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n","mpl.findpos = function(e) {\n","    //this section is from http://www.quirksmode.org/js/events_properties.html\n","    var targ;\n","    if (!e)\n","        e = window.event;\n","    if (e.target)\n","        targ = e.target;\n","    else if (e.srcElement)\n","        targ = e.srcElement;\n","    if (targ.nodeType == 3) // defeat Safari bug\n","        targ = targ.parentNode;\n","\n","    // jQuery normalizes the pageX and pageY\n","    // pageX,Y are the mouse positions relative to the document\n","    // offset() returns the position of the element relative to the document\n","    var x = e.pageX - $(targ).offset().left;\n","    var y = e.pageY - $(targ).offset().top;\n","\n","    return {\"x\": x, \"y\": y};\n","};\n","\n","/*\n"," * return a copy of an object with only non-object keys\n"," * we need this to avoid circular references\n"," * http://stackoverflow.com/a/24161582/3208463\n"," */\n","function simpleKeys (original) {\n","  return Object.keys(original).reduce(function (obj, key) {\n","    if (typeof original[key] !== 'object')\n","        obj[key] = original[key]\n","    return obj;\n","  }, {});\n","}\n","\n","mpl.figure.prototype.mouse_event = function(event, name) {\n","    var canvas_pos = mpl.findpos(event)\n","\n","    if (name === 'button_press')\n","    {\n","        this.canvas.focus();\n","        this.canvas_div.focus();\n","    }\n","\n","    var x = canvas_pos.x * mpl.ratio;\n","    var y = canvas_pos.y * mpl.ratio;\n","\n","    this.send_message(name, {x: x, y: y, button: event.button,\n","                             step: event.step,\n","                             guiEvent: simpleKeys(event)});\n","\n","    /* This prevents the web browser from automatically changing to\n","     * the text insertion cursor when the button is pressed.  We want\n","     * to control all of the cursor setting manually through the\n","     * 'cursor' event from matplotlib */\n","    event.preventDefault();\n","    return false;\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    // Handle any extra behaviour associated with a key event\n","}\n","\n","mpl.figure.prototype.key_event = function(event, name) {\n","\n","    // Prevent repeat events\n","    if (name == 'key_press')\n","    {\n","        if (event.which === this._key)\n","            return;\n","        else\n","            this._key = event.which;\n","    }\n","    if (name == 'key_release')\n","        this._key = null;\n","\n","    var value = '';\n","    if (event.ctrlKey && event.which != 17)\n","        value += \"ctrl+\";\n","    if (event.altKey && event.which != 18)\n","        value += \"alt+\";\n","    if (event.shiftKey && event.which != 16)\n","        value += \"shift+\";\n","\n","    value += 'k';\n","    value += event.which.toString();\n","\n","    this._key_event_extra(event, name);\n","\n","    this.send_message(name, {key: value,\n","                             guiEvent: simpleKeys(event)});\n","    return false;\n","}\n","\n","mpl.figure.prototype.toolbar_button_onclick = function(name) {\n","    if (name == 'download') {\n","        this.handle_save(this, null);\n","    } else {\n","        this.send_message(\"toolbar_button\", {name: name});\n","    }\n","};\n","\n","mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n","    this.message.textContent = tooltip;\n","};\n","mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n","\n","mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n","\n","mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n","    // Create a \"websocket\"-like object which calls the given IPython comm\n","    // object with the appropriate methods. Currently this is a non binary\n","    // socket, so there is still some room for performance tuning.\n","    var ws = {};\n","\n","    ws.close = function() {\n","        comm.close()\n","    };\n","    ws.send = function(m) {\n","        //console.log('sending', m);\n","        comm.send(m);\n","    };\n","    // Register the callback with on_msg.\n","    comm.on_msg(function(msg) {\n","        //console.log('receiving', msg['content']['data'], msg);\n","        // Pass the mpl event to the overridden (by mpl) onmessage function.\n","        ws.onmessage(msg['content']['data'])\n","    });\n","    return ws;\n","}\n","\n","mpl.mpl_figure_comm = function(comm, msg) {\n","    // This is the function which gets called when the mpl process\n","    // starts-up an IPython Comm through the \"matplotlib\" channel.\n","\n","    var id = msg.content.data.id;\n","    // Get hold of the div created by the display call when the Comm\n","    // socket was opened in Python.\n","    var element = $(\"#\" + id);\n","    var ws_proxy = comm_websocket_adapter(comm)\n","\n","    function ondownload(figure, format) {\n","        window.open(figure.imageObj.src);\n","    }\n","\n","    var fig = new mpl.figure(id, ws_proxy,\n","                           ondownload,\n","                           element.get(0));\n","\n","    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n","    // web socket which is closed, not our websocket->open comm proxy.\n","    ws_proxy.onopen();\n","\n","    fig.parent_element = element.get(0);\n","    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n","    if (!fig.cell_info) {\n","        console.error(\"Failed to find cell for figure\", id, fig);\n","        return;\n","    }\n","\n","    var output_index = fig.cell_info[2]\n","    var cell = fig.cell_info[0];\n","\n","};\n","\n","mpl.figure.prototype.handle_close = function(fig, msg) {\n","    var width = fig.canvas.width/mpl.ratio\n","    fig.root.unbind('remove')\n","\n","    // Update the output cell to use the data from the current canvas.\n","    fig.push_to_output();\n","    var dataURL = fig.canvas.toDataURL();\n","    // Re-enable the keyboard manager in IPython - without this line, in FF,\n","    // the notebook keyboard shortcuts fail.\n","    IPython.keyboard_manager.enable()\n","    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n","    fig.close_ws(fig, msg);\n","}\n","\n","mpl.figure.prototype.close_ws = function(fig, msg){\n","    fig.send_message('closing', msg);\n","    // fig.ws.close()\n","}\n","\n","mpl.figure.prototype.push_to_output = function(remove_interactive) {\n","    // Turn the data on the canvas into data in the output cell.\n","    var width = this.canvas.width/mpl.ratio\n","    var dataURL = this.canvas.toDataURL();\n","    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n","}\n","\n","mpl.figure.prototype.updated_canvas_event = function() {\n","    // Tell IPython that the notebook contents must change.\n","    IPython.notebook.set_dirty(true);\n","    this.send_message(\"ack\", {});\n","    var fig = this;\n","    // Wait a second, then push the new image to the DOM so\n","    // that it is saved nicely (might be nice to debounce this).\n","    setTimeout(function () { fig.push_to_output() }, 1000);\n","}\n","\n","mpl.figure.prototype._init_toolbar = function() {\n","    var fig = this;\n","\n","    var nav_element = $('<div/>');\n","    nav_element.attr('style', 'width: 100%');\n","    this.root.append(nav_element);\n","\n","    // Define a callback function for later on.\n","    function toolbar_event(event) {\n","        return fig.toolbar_button_onclick(event['data']);\n","    }\n","    function toolbar_mouse_event(event) {\n","        return fig.toolbar_button_onmouseover(event['data']);\n","    }\n","\n","    for(var toolbar_ind in mpl.toolbar_items){\n","        var name = mpl.toolbar_items[toolbar_ind][0];\n","        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n","        var image = mpl.toolbar_items[toolbar_ind][2];\n","        var method_name = mpl.toolbar_items[toolbar_ind][3];\n","\n","        if (!name) { continue; };\n","\n","        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n","        button.click(method_name, toolbar_event);\n","        button.mouseover(tooltip, toolbar_mouse_event);\n","        nav_element.append(button);\n","    }\n","\n","    // Add the status bar.\n","    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n","    nav_element.append(status_bar);\n","    this.message = status_bar[0];\n","\n","    // Add the close button to the window.\n","    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n","    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n","    button.click(function (evt) { fig.handle_close(fig, {}); } );\n","    button.mouseover('Stop Interaction', toolbar_mouse_event);\n","    buttongrp.append(button);\n","    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n","    titlebar.prepend(buttongrp);\n","}\n","\n","mpl.figure.prototype._root_extra_style = function(el){\n","    var fig = this\n","    el.on(\"remove\", function(){\n","\tfig.close_ws(fig, {});\n","    });\n","}\n","\n","mpl.figure.prototype._canvas_extra_style = function(el){\n","    // this is important to make the div 'focusable\n","    el.attr('tabindex', 0)\n","    // reach out to IPython and tell the keyboard manager to turn it's self\n","    // off when our div gets focus\n","\n","    // location in version 3\n","    if (IPython.notebook.keyboard_manager) {\n","        IPython.notebook.keyboard_manager.register_events(el);\n","    }\n","    else {\n","        // location in version 2\n","        IPython.keyboard_manager.register_events(el);\n","    }\n","\n","}\n","\n","mpl.figure.prototype._key_event_extra = function(event, name) {\n","    var manager = IPython.notebook.keyboard_manager;\n","    if (!manager)\n","        manager = IPython.keyboard_manager;\n","\n","    // Check for shift+enter\n","    if (event.shiftKey && event.which == 13) {\n","        this.canvas_div.blur();\n","        // select the cell after this one\n","        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n","        IPython.notebook.select(index + 1);\n","    }\n","}\n","\n","mpl.figure.prototype.handle_save = function(fig, msg) {\n","    fig.ondownload(fig, null);\n","}\n","\n","\n","mpl.find_output_cell = function(html_output) {\n","    // Return the cell and output element which can be found *uniquely* in the notebook.\n","    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n","    // IPython event is triggered only after the cells have been serialised, which for\n","    // our purposes (turning an active figure into a static one), is too late.\n","    var cells = IPython.notebook.get_cells();\n","    var ncells = cells.length;\n","    for (var i=0; i<ncells; i++) {\n","        var cell = cells[i];\n","        if (cell.cell_type === 'code'){\n","            for (var j=0; j<cell.output_area.outputs.length; j++) {\n","                var data = cell.output_area.outputs[j];\n","                if (data.data) {\n","                    // IPython >= 3 moved mimebundle to data attribute of output\n","                    data = data.data;\n","                }\n","                if (data['text/html'] == html_output) {\n","                    return [cell, data, j];\n","                }\n","            }\n","        }\n","    }\n","}\n","\n","// Register the function which deals with the matplotlib target/channel.\n","// The kernel may be null if the page has been refreshed.\n","if (IPython.notebook.kernel != null) {\n","    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n","}\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div id='51949bd9-ad52-45b6-bf25-19f22df389ff'></div>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/cbook/__init__.py\", line 196, in process\n","    func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/animation.py\", line 1467, in _stop\n","    self.event_source.remove_callback(self._loop_delay)\n","AttributeError: 'NoneType' object has no attribute 'remove_callback'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5JZxchRSGLK7","executionInfo":{"status":"ok","timestamp":1676896065029,"user_tz":-480,"elapsed":57,"user":{"displayName":"CLPT Thesis Bois","userId":"09984672890551432786"}}},"execution_count":31,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOLPywQmwLrl32vVSLcrgNU"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"64285efdca534a1788411dceda383496":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":["widget-interact"],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_54fe7eefe59649579a9cd0d4c44ec649","IPY_MODEL_95aca59cd8374097b31e9f6cf67a8f3d"],"layout":"IPY_MODEL_7f5754ac21f44b1683e6f1dcc16800c1"}},"54fe7eefe59649579a9cd0d4c44ec649":{"model_module":"@jupyter-widgets/controls","model_name":"IntSliderModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntSliderModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"IntSliderView","continuous_update":true,"description":"k","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_6d0b25c554f647b49bda7dcf3c5e1944","max":303,"min":0,"orientation":"horizontal","readout":true,"readout_format":"d","step":1,"style":"IPY_MODEL_13c00f3803a946cd9542adac0dd1f05e","value":0}},"95aca59cd8374097b31e9f6cf67a8f3d":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_d10f302810264cb4a24776a0c53c12b4","msg_id":"","outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}},"7f5754ac21f44b1683e6f1dcc16800c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d0b25c554f647b49bda7dcf3c5e1944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13c00f3803a946cd9542adac0dd1f05e":{"model_module":"@jupyter-widgets/controls","model_name":"SliderStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"SliderStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":"","handle_color":null}},"d10f302810264cb4a24776a0c53c12b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}